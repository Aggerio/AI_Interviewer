import { Segment } from '../speechly';
import { DecoderState, EventCallbacks, ContextOptions, VadOptions, AudioProcessorParameters, StreamOptions, ResolvedDecoderOptions } from './types';
/**
 * A client for Speechly Spoken Language Understanding (SLU) API. The client handles initializing the websocket
 * connection to Speechly API, sending control events and audio stream. It reads and dispatches the responses
 * through a high-level API for interacting with so-called speech segments.
 * @internal
 */
export declare class CloudDecoder {
    private readonly debug;
    private readonly logSegments;
    private readonly projectId?;
    private readonly appId?;
    private readonly storage?;
    private readonly apiClient;
    private readonly loginUrl;
    private readonly deviceId;
    private readonly apiUrl;
    streamOptions: StreamOptions;
    private resolveStopStream?;
    private activeContexts;
    private readonly audioContexts;
    private readonly maxReconnectAttemptCount;
    private connectAttempt;
    private connectPromise;
    private authToken?;
    private readonly cbs;
    sampleRate: number;
    state: DecoderState;
    constructor(options: ResolvedDecoderOptions);
    private getReconnectDelayMs;
    private sleep;
    /**
     * Connect to Speechly backend.
     * This function will be called by initialize if not manually called earlier.
     * Calling connect() immediately after constructor and setting callbacks allows
     * prewarming the connection, resulting in less noticeable waits for the user.
     */
    connect(): Promise<void>;
    /**
     * Control audio processor parameters
     * @param ap - Audio processor parameters to adjust
     */
    adjustAudioProcessor(ap: AudioProcessorParameters): void;
    /**
     * Closes the client by closing the API connection.
     */
    close(): Promise<void>;
    startStream(streamOptions: StreamOptions): Promise<void>;
    stopStream(): Promise<void>;
    private waitResults;
    /**
     * Starts a new SLU context by sending a start context event to the API.
     */
    startContext(options?: ContextOptions): Promise<string>;
    /**
     * Send audio array.
     */
    sendAudio(audio: Float32Array): void;
    /**
     * Stops current SLU context by sending a stop context event to the API and muting the microphone
     * delayed by contextStopDelay = 250 ms
     */
    stopContext(stopDelayMs: number): Promise<string>;
    /**
     * Stops current context and immediately starts a new SLU context
     * by sending a start context event to the API and unmuting the microphone.
     * @param options - any custom options for the audio processing.
     */
    switchContext(options: ContextOptions): Promise<string>;
    registerListener(listener: EventCallbacks): void;
    initAudioProcessor(sourceSampleRate: number, frameMillis: number, historyFrames: number, vadOptions?: VadOptions): Promise<void>;
    useSharedArrayBuffers(controlSAB: any, dataSAB: any): void;
    setContextOptions(options: ContextOptions): Promise<void>;
    private readonly handleWebsocketResponse;
    private readonly handleSegmentUpdate;
    private readonly handleWebsocketClosure;
    private reconnect;
    private advanceState;
    private setState;
    /**
     * @returns Array of Segments since last startStream if preserveSegment options was used
     */
    getSegments(): Segment[];
}
