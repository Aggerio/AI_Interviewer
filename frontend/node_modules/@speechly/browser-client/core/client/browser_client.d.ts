import { DecoderState, DecoderOptions, ContextOptions, AudioProcessorParameters, StreamOptions } from './types';
import { Segment, Word, Entity, Intent } from '../speechly';
/**
 * Speechly BrowserClient streams audio containing speech for cloud processing and
 * provides the results of automatic speech recogition (ASR) and natural langugage understanding (NLU) via callbacks.
 *
 * Usage:
 *
 * - Create a BrowserClient instance with {@link DecoderOptions} containing a valid appId from https://api.speechly.com/dashboard.
 * - Create and initialize a {@link BrowserMicrophone} instance and {@link attach} its mediaStream to the BrowserClient instance.
 * - Control processing manually with {@link start} and {@link stop}. Alternatively, you can enable automatic control by initializing BrowserClient with {@link VadOptions} defined in the {@link DecoderOptions}.
 * - Read the ASR/NLU result {@link Segment} by providing a custom handler for the {@link onSegmentChange} callback.
 *
 * Alternatively, you can create the BrowserClient instance and process audio files (binary data) using {@link uploadAudioData}.
 * @public
 */
export declare class BrowserClient {
    private readonly contextStopDelay;
    private readonly nativeResamplingSupported;
    private readonly debug;
    private readonly useSAB;
    private readonly isSafari;
    private readonly isMobileSafari;
    private readonly decoder;
    private readonly callbacks;
    private audioContext?;
    private initialized;
    private audioProcessorInitialized;
    private isStreaming;
    private active;
    private speechlyNode?;
    private audioProcessor?;
    private stream?;
    private listeningPromise;
    private readonly decoderOptions;
    private streamOptions;
    private stats;
    /**
     * Create a new BrowserClient instance.
     *
     * @param customOptions - any custom options for BrowserClient and the enclosed CloudDecoder.
     */
    constructor(customOptions: DecoderOptions);
    /**
     * Connect to cloud, create an AudioContext for receiving audio samples from a MediaStream
     * and initialize a worker for audio processing and bi-directional streaming to the cloud.
     */
    initialize(options?: {
        mediaStream?: MediaStream;
    }): Promise<void>;
    /**
     * Attach a MediaStream to the client, enabling the client to send the audio to the
     * Speechly API for processing. The processing is activated by calling
     * {@link BrowserClient.start} and deactivated by calling {@link BrowserClient.stop}.
     */
    attach(mediaStream: MediaStream): Promise<void>;
    /**
     * @returns Whether the client is processing audio at the moment.
     */
    isActive(): boolean;
    /**
     * Starts a new audio context, returning it's id to use for matching received responses.
     * If an active context already exists, an error is thrown.
     *
     * @param options - any custom options for the audio processing.
     * @returns The contextId of the active audio context
     */
    start(options?: ContextOptions): Promise<string>;
    /**
     * Stops the current audio context and deactivates the audio processing pipeline.
     * If there is no active audio context, a warning is logged to console.
     */
    stop(stopDelayMs?: number): Promise<string>;
    /**
     * Sets the default context options (appId, inference parameters, timezone). New audio contexts
     * use these options until new options are provided. Decoder's functions startContext() can
     * also override the options per function call.
     */
    setContextOptions(options: ContextOptions): Promise<void>;
    /**
     * Control audio processor parameters like VAD
     * @param ap - Audio processor parameters to adjust
     */
    adjustAudioProcessor(ap: AudioProcessorParameters): void;
    /**
     * Upload an audio binary (like .wav) to the cloud for automatic speech recogition (ASR) and natural langugage understanding (NLU).
     * Callbacks are fired as the processing advances.
     *
     * @param audioData - audio data in a binary format. Will be decoded.
     * @param options - any custom options for the audio processing.
     * @returns array of segments containing the final results of speech recognition (ASR and NLU).
     */
    uploadAudioData(audioData: ArrayBuffer, options?: ContextOptions): Promise<Segment[]>;
    /**
     * `startStream` is used to indicate start of continuous audio stream.
     * It resets the stream sample counters and history.
     * BrowserClient internally calls `startStream` upon `initialize` and `start` so it's not needed unless you've manually called `stopStream` and want to resume audio processing afterwards.
     * @param streamOptionOverrides - options for stream processing
     */
    startStream(streamOptionOverrides?: Partial<StreamOptions>): Promise<void>;
    /**
     * `stopStream` is used to indicate end of continuous audio stream.
     * It ensures that all of the internal audio buffers are flushed for processing.
     * BrowserClient internally calls `stopStream` upon `stop` so it's not needed unless then source audio stream is no longer available or you manually want to pause audio processing.
     * Use `startStream` to resume audio processing afterwards.
     */
    stopStream(): Promise<void>;
    private queueTask;
    private autoControlListening;
    private autoControlStream;
    private handleStateChange;
    /**
     * Detach or disconnect the client from the audio source.
     */
    detach(): Promise<void>;
    /**
     * Closes the client, detaching from any audio source and disconnecting any audio
     * processors.
     */
    close(): Promise<void>;
    private sleep;
    private handleAudio;
    /**
     * Adds a listener for start events
     * @param cb - the callback to invoke on context start
     */
    onStart(cb: (contextId: string) => void): void;
    /**
     * Adds a listener for stop events
     * @param cb - the callback to invoke on context stop
     */
    onStop(cb: (contextId: string) => void): void;
    /**
     * Adds a listener for current segment change events.
     * @param cb - the callback to invoke on segment change events.
     */
    onSegmentChange(cb: (segment: Segment) => void): void;
    /**
     * Adds a listener for transcript responses from the API.
     * @param cb - the callback to invoke on a transcript response.
     */
    onTranscript(cb: (contextId: string, segmentId: number, word: Word) => void): void;
    /**
     * Adds a listener for entity responses from the API.
     * @param cb - the callback to invoke on an entity response.
     */
    onEntity(cb: (contextId: string, segmentId: number, entity: Entity) => void): void;
    /**
     * Adds a listener for intent responses from the API.
     * @param cb - the callback to invoke on an intent response.
     */
    onIntent(cb: (contextId: string, segmentId: number, intent: Intent) => void): void;
    /**
     * Adds a listener for tentative transcript responses from the API.
     * @param cb - the callback to invoke on a tentative transcript response.
     */
    onTentativeTranscript(cb: (contextId: string, segmentId: number, words: Word[], text: string) => void): void;
    /**
     * Adds a listener for tentative entities responses from the API.
     * @param cb - the callback to invoke on a tentative entities response.
     */
    onTentativeEntities(cb: (contextId: string, segmentId: number, entities: Entity[]) => void): void;
    /**
     * Adds a listener for tentative intent responses from the API.
     * @param cb - the callback to invoke on a tentative intent response.
     */
    onTentativeIntent(cb: (contextId: string, segmentId: number, intent: Intent) => void): void;
    /**
     * Adds a listener for the state changes of the client.
     * @param cb - the callback to invoke on a client state change.
     */
    onStateChange(cb: (state: DecoderState) => void): void;
}
