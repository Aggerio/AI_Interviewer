{"ast":null,"code":"var _jsxFileName = \"/home/aggerio/code_playground/ai_interviewer/frontend/src/components/SpeechToText.jsx\",\n  _s = $RefreshSig$();\n// import React, { useEffect } from 'react';\n// import { createSpeechlySpeechRecognition } from '@speechly/speech-recognition-polyfill';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n// // const appId = '67912827-d6a0-4329-ace1-99eb1f1052ac';\n// const appId = process.env.REACT_APP_SPEECHLY_ID;\n// const SpeechlySpeechRecognition = createSpeechlySpeechRecognition(appId);\n// SpeechRecognition.applyPolyfill(SpeechlySpeechRecognition);\n\n// const SpeechToText = () => {\n//   const {\n//     transcript,\n//     listening,\n//     browserSupportsSpeechRecognition\n//   } = useSpeechRecognition();\n//   const startListening = () => SpeechRecognition.startListening({ continuous: true });\n\n//   useEffect(() => {\n//     startListening();\n//     return () => {\n//       SpeechRecognition.stopListening();\n//     }\n//   }, []);\n\n//   if (!browserSupportsSpeechRecognition) {\n//     return <span>Browser doesn't support speech recognition.</span>;\n//   }\n//   else {\n\n//     return (\n//       <div className=\"w-[800px] h-[200px] bg-red-300\">\n//         {/* <p>Microphone: {listening ? 'on' : 'off'}</p> */}\n//         {/* <button */}\n//         {/*   onTouchStart={startListening} */}\n//         {/*   onMouseDown={startListening} */}\n//         {/*   onTouchEnd={SpeechRecognition.stopListening} */}\n//         {/*   onMouseUp={SpeechRecognition.stopListening} */}\n//         {/* >Hold to talk</button> */}\n//         <p>{transcript}</p>\n//       </div>\n//     );\n//   };\n// }\n// export default SpeechToText;\n\nimport React, { useEffect, useState, useRef } from \"react\";\nimport * as io from \"socket.io-client\";\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst sampleRate = 16000;\nconst getMediaStream = () => navigator.mediaDevices.getUserMedia({\n  audio: {\n    deviceId: \"default\",\n    sampleRate: sampleRate,\n    sampleSize: 16,\n    channelCount: 1\n  },\n  video: false\n});\nconst SpeechToText = () => {\n  _s();\n  const [connection, setConnection] = useState();\n  const [currentRecognition, setCurrentRecognition] = useState();\n  const [recognitionHistory, setRecognitionHistory] = useState([]);\n  const [isRecording, setIsRecording] = useState(false);\n  const [recorder, setRecorder] = useState();\n  const processorRef = useRef();\n  const audioContextRef = useRef();\n  const audioInputRef = useRef();\n  const speechRecognized = data => {\n    if (data.isFinal) {\n      setCurrentRecognition(\"...\");\n      // setRecognitionHistory((old) => [data.text, ...old]);\n      setRecognitionHistory(old => [...old, data.text]);\n    } else setCurrentRecognition(data.text + \"...\");\n  };\n  useEffect(() => {\n    console.log(\"\\n\\nrecognitionHistory\", recognitionHistory);\n  }, [recognitionHistory]);\n  const connect = () => {\n    console.log(\"Starting connection\");\n    connection === null || connection === void 0 ? void 0 : connection.disconnect();\n    const socket = io.connect(\"http://localhost:8081\");\n    socket.on(\"connect\", () => {\n      console.log(\"connected\", socket.id);\n      setConnection(socket);\n    });\n    socket.emit(\"send_message\", \"hello world\");\n    socket.emit(\"startGoogleCloudStream\");\n    socket.on(\"receive_message\", data => {\n      console.log(\"received message\", data);\n    });\n    socket.on(\"receive_audio_text\", data => {\n      speechRecognized(data);\n      console.log(\"received audio text\", data);\n    });\n    socket.on(\"disconnect\", () => {\n      console.log(\"disconnected\", socket.id);\n    });\n  };\n  const disconnect = () => {\n    var _processorRef$current, _audioInputRef$curren, _audioContextRef$curr;\n    if (!connection) return;\n    connection === null || connection === void 0 ? void 0 : connection.emit(\"endGoogleCloudStream\");\n    connection === null || connection === void 0 ? void 0 : connection.disconnect();\n    (_processorRef$current = processorRef.current) === null || _processorRef$current === void 0 ? void 0 : _processorRef$current.disconnect();\n    (_audioInputRef$curren = audioInputRef.current) === null || _audioInputRef$curren === void 0 ? void 0 : _audioInputRef$curren.disconnect();\n    (_audioContextRef$curr = audioContextRef.current) === null || _audioContextRef$curr === void 0 ? void 0 : _audioContextRef$curr.close();\n    setConnection(undefined);\n    setRecorder(undefined);\n    setIsRecording(false);\n\n    //Send the transcript to the chatgpt interview response server \n    // and reset the conversation history\n    axios.post('http://localhost:5002/response', {\n      'transcript': recognitionHistory\n    });\n    setCurrentRecognition(\"\");\n    setRecognitionHistory([]);\n  };\n  useEffect(() => {\n    (async () => {\n      if (connection) {\n        if (isRecording) {\n          return;\n        }\n        const stream = await getMediaStream();\n        audioContextRef.current = new window.AudioContext();\n        await audioContextRef.current.audioWorklet.addModule(\"/src/worklets/recorderWorkletProcessor.js\");\n        audioContextRef.current.resume();\n        audioInputRef.current = audioContextRef.current.createMediaStreamSource(stream);\n        processorRef.current = new AudioWorkletNode(audioContextRef.current, \"recorder.worklet\");\n        processorRef.current.connect(audioContextRef.current.destination);\n        audioContextRef.current.resume();\n        audioInputRef.current.connect(processorRef.current);\n        processorRef.current.port.onmessage = event => {\n          const audioData = event.data;\n          connection.emit(\"send_audio_data\", {\n            audio: audioData\n          });\n        };\n        setIsRecording(true);\n      } else {\n        console.error(\"No connection\");\n      }\n    })();\n    return () => {\n      if (isRecording) {\n        var _processorRef$current2, _audioInputRef$curren2, _audioContextRef$curr2;\n        (_processorRef$current2 = processorRef.current) === null || _processorRef$current2 === void 0 ? void 0 : _processorRef$current2.disconnect();\n        (_audioInputRef$curren2 = audioInputRef.current) === null || _audioInputRef$curren2 === void 0 ? void 0 : _audioInputRef$curren2.disconnect();\n        if (((_audioContextRef$curr2 = audioContextRef.current) === null || _audioContextRef$curr2 === void 0 ? void 0 : _audioContextRef$curr2.state) !== \"closed\") {\n          var _audioContextRef$curr3;\n          (_audioContextRef$curr3 = audioContextRef.current) === null || _audioContextRef$curr3 === void 0 ? void 0 : _audioContextRef$curr3.close();\n        }\n      }\n    };\n  }, [connection, isRecording, recorder]);\n\n  //   return (\n  //     <React.Fragment>\n  //       <Container className=\"py-5 text-center\">\n  //         <Container fluid className=\"py-5 bg-primary text-light text-center \">\n  //           <Container>\n  //             <Button\n  //               className={isRecording ? \"btn-danger\" : \"btn-outline-light\"}\n  //               onClick={connect}\n  //               disabled={isRecording}\n  //             >\n  //               Start\n  //             </Button>\n  //             <Button\n  //               className=\"btn-outline-light\"\n  //               onClick={disconnect}\n  //               disabled={!isRecording}\n  //             >\n  //               Stop\n  //             </Button>\n  //           </Container>\n  //         </Container>\n  //         <Container className=\"py-5 text-center\">\n  //           {recognitionHistory.map((tx, idx) => (\n  //             <p key={idx}>{tx}</p>\n  //           ))}\n  //           <p>{currentRecognition}</p>\n  //         </Container>\n  //       </Container>\n  //     </React.Fragment>\n  //   );\n  // };\n\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"py-5 text-center\",\n    children: [/*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"py-5 bg-primary text-light text-center\",\n      children: /*#__PURE__*/_jsxDEV(\"div\", {\n        className: \"space-x-4\",\n        children: [/*#__PURE__*/_jsxDEV(\"button\", {\n          className: `${isRecording ? \"bg-red-500\" : \"bg-white text-primary border border-light\"} px-4 py-2 rounded`,\n          onClick: connect,\n          disabled: isRecording,\n          children: \"Start\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 219,\n          columnNumber: 11\n        }, this), /*#__PURE__*/_jsxDEV(\"button\", {\n          className: `bg-white text-primary border border-light px-4 py-2 rounded`,\n          onClick: disconnect,\n          disabled: !isRecording,\n          children: \"Stop\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 227,\n          columnNumber: 11\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 218,\n        columnNumber: 9\n      }, this)\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 217,\n      columnNumber: 7\n    }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"py-5 text-center text-white\",\n      children: [recognitionHistory.map((tx, idx) => /*#__PURE__*/_jsxDEV(\"p\", {\n        children: tx\n      }, idx, false, {\n        fileName: _jsxFileName,\n        lineNumber: 238,\n        columnNumber: 11\n      }, this)), /*#__PURE__*/_jsxDEV(\"p\", {\n        children: currentRecognition\n      }, void 0, false, {\n        fileName: _jsxFileName,\n        lineNumber: 240,\n        columnNumber: 9\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 236,\n      columnNumber: 7\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 216,\n    columnNumber: 5\n  }, this);\n};\n_s(SpeechToText, \"ONOj++HxDqkMKHSkHlVQQE2LIWM=\");\n_c = SpeechToText;\nexport default SpeechToText;\nvar _c;\n$RefreshReg$(_c, \"SpeechToText\");","map":{"version":3,"names":["React","useEffect","useState","useRef","io","jsxDEV","_jsxDEV","sampleRate","getMediaStream","navigator","mediaDevices","getUserMedia","audio","deviceId","sampleSize","channelCount","video","SpeechToText","_s","connection","setConnection","currentRecognition","setCurrentRecognition","recognitionHistory","setRecognitionHistory","isRecording","setIsRecording","recorder","setRecorder","processorRef","audioContextRef","audioInputRef","speechRecognized","data","isFinal","old","text","console","log","connect","disconnect","socket","on","id","emit","_processorRef$current","_audioInputRef$curren","_audioContextRef$curr","current","close","undefined","axios","post","stream","window","AudioContext","audioWorklet","addModule","resume","createMediaStreamSource","AudioWorkletNode","destination","port","onmessage","event","audioData","error","_processorRef$current2","_audioInputRef$curren2","_audioContextRef$curr2","state","_audioContextRef$curr3","className","children","onClick","disabled","fileName","_jsxFileName","lineNumber","columnNumber","map","tx","idx","_c","$RefreshReg$"],"sources":["/home/aggerio/code_playground/ai_interviewer/frontend/src/components/SpeechToText.jsx"],"sourcesContent":["// import React, { useEffect } from 'react';\n// import { createSpeechlySpeechRecognition } from '@speechly/speech-recognition-polyfill';\n// import SpeechRecognition, { useSpeechRecognition } from 'react-speech-recognition';\n\n\n// // const appId = '67912827-d6a0-4329-ace1-99eb1f1052ac';\n// const appId = process.env.REACT_APP_SPEECHLY_ID;\n// const SpeechlySpeechRecognition = createSpeechlySpeechRecognition(appId);\n// SpeechRecognition.applyPolyfill(SpeechlySpeechRecognition);\n\n// const SpeechToText = () => {\n//   const {\n//     transcript,\n//     listening,\n//     browserSupportsSpeechRecognition\n//   } = useSpeechRecognition();\n//   const startListening = () => SpeechRecognition.startListening({ continuous: true });\n\n//   useEffect(() => {\n//     startListening();\n//     return () => {\n//       SpeechRecognition.stopListening();\n//     }\n//   }, []);\n\n//   if (!browserSupportsSpeechRecognition) {\n//     return <span>Browser doesn't support speech recognition.</span>;\n//   }\n//   else {\n\n//     return (\n//       <div className=\"w-[800px] h-[200px] bg-red-300\">\n//         {/* <p>Microphone: {listening ? 'on' : 'off'}</p> */}\n//         {/* <button */}\n//         {/*   onTouchStart={startListening} */}\n//         {/*   onMouseDown={startListening} */}\n//         {/*   onTouchEnd={SpeechRecognition.stopListening} */}\n//         {/*   onMouseUp={SpeechRecognition.stopListening} */}\n//         {/* >Hold to talk</button> */}\n//         <p>{transcript}</p>\n//       </div>\n//     );\n//   };\n// }\n// export default SpeechToText;\n\n\n\nimport React, { useEffect, useState, useRef } from \"react\";\nimport * as io from \"socket.io-client\";\n\nconst sampleRate = 16000;\n\nconst getMediaStream = () =>\n  navigator.mediaDevices.getUserMedia({\n    audio: {\n      deviceId: \"default\",\n      sampleRate: sampleRate,\n      sampleSize: 16,\n      channelCount: 1,\n    },\n    video: false,\n  });\n\nconst SpeechToText = () => {\n  const [connection, setConnection] = useState();\n  const [currentRecognition, setCurrentRecognition] = useState();\n  const [recognitionHistory, setRecognitionHistory] = useState([]);\n  const [isRecording, setIsRecording] = useState(false);\n  const [recorder, setRecorder] = useState();\n  const processorRef = useRef();\n  const audioContextRef = useRef();\n  const audioInputRef = useRef();\n\n  const speechRecognized = (data) => {\n    if (data.isFinal) {\n      setCurrentRecognition(\"...\");\n      // setRecognitionHistory((old) => [data.text, ...old]);\n      setRecognitionHistory((old) => [...old, data.text]);\n    } else setCurrentRecognition(data.text + \"...\");\n  };\n\n  useEffect(() => {\n    console.log(\"\\n\\nrecognitionHistory\", recognitionHistory);\n  }, [recognitionHistory]);\n\n  const connect = () => {\n    console.log(\"Starting connection\");\n    connection?.disconnect();\n    const socket = io.connect(\"http://localhost:8081\");\n    socket.on(\"connect\", () => {\n      console.log(\"connected\", socket.id);\n      setConnection(socket);\n    });\n\n    socket.emit(\"send_message\", \"hello world\");\n\n    socket.emit(\"startGoogleCloudStream\");\n\n    socket.on(\"receive_message\", (data) => {\n      console.log(\"received message\", data);\n    });\n\n    socket.on(\"receive_audio_text\", (data) => {\n      speechRecognized(data);\n      console.log(\"received audio text\", data);\n    });\n\n    socket.on(\"disconnect\", () => {\n      console.log(\"disconnected\", socket.id);\n    });\n  };\n\n  const disconnect = () => {\n    if (!connection) return;\n    connection?.emit(\"endGoogleCloudStream\");\n    connection?.disconnect();\n    processorRef.current?.disconnect();\n    audioInputRef.current?.disconnect();\n    audioContextRef.current?.close();\n    setConnection(undefined);\n    setRecorder(undefined);\n    setIsRecording(false);\n\n    //Send the transcript to the chatgpt interview response server \n    // and reset the conversation history\n    axios.post('http://localhost:5002/response', { 'transcript': recognitionHistory });\n    setCurrentRecognition(\"\");\n    setRecognitionHistory([]);\n  };\n\n  useEffect(() => {\n    (async () => {\n      if (connection) {\n        if (isRecording) {\n          return;\n        }\n\n        const stream = await getMediaStream();\n\n        audioContextRef.current = new window.AudioContext();\n\n        await audioContextRef.current.audioWorklet.addModule(\n          \"/src/worklets/recorderWorkletProcessor.js\"\n        );\n\n        audioContextRef.current.resume();\n\n        audioInputRef.current =\n          audioContextRef.current.createMediaStreamSource(stream);\n\n        processorRef.current = new AudioWorkletNode(\n          audioContextRef.current,\n          \"recorder.worklet\"\n        );\n\n        processorRef.current.connect(audioContextRef.current.destination);\n        audioContextRef.current.resume();\n\n        audioInputRef.current.connect(processorRef.current);\n\n        processorRef.current.port.onmessage = (event) => {\n          const audioData = event.data;\n          connection.emit(\"send_audio_data\", { audio: audioData });\n        };\n        setIsRecording(true);\n      } else {\n        console.error(\"No connection\");\n      }\n    })();\n    return () => {\n      if (isRecording) {\n        processorRef.current?.disconnect();\n        audioInputRef.current?.disconnect();\n        if (audioContextRef.current?.state !== \"closed\") {\n          audioContextRef.current?.close();\n        }\n      }\n    };\n  }, [connection, isRecording, recorder]);\n\n  //   return (\n  //     <React.Fragment>\n  //       <Container className=\"py-5 text-center\">\n  //         <Container fluid className=\"py-5 bg-primary text-light text-center \">\n  //           <Container>\n  //             <Button\n  //               className={isRecording ? \"btn-danger\" : \"btn-outline-light\"}\n  //               onClick={connect}\n  //               disabled={isRecording}\n  //             >\n  //               Start\n  //             </Button>\n  //             <Button\n  //               className=\"btn-outline-light\"\n  //               onClick={disconnect}\n  //               disabled={!isRecording}\n  //             >\n  //               Stop\n  //             </Button>\n  //           </Container>\n  //         </Container>\n  //         <Container className=\"py-5 text-center\">\n  //           {recognitionHistory.map((tx, idx) => (\n  //             <p key={idx}>{tx}</p>\n  //           ))}\n  //           <p>{currentRecognition}</p>\n  //         </Container>\n  //       </Container>\n  //     </React.Fragment>\n  //   );\n  // };\n\n\n  return (\n    <div className=\"py-5 text-center\">\n      <div className=\"py-5 bg-primary text-light text-center\">\n        <div className=\"space-x-4\">\n          <button\n            className={`${isRecording ? \"bg-red-500\" : \"bg-white text-primary border border-light\"\n              } px-4 py-2 rounded`}\n            onClick={connect}\n            disabled={isRecording}\n          >\n            Start\n          </button>\n          <button\n            className={`bg-white text-primary border border-light px-4 py-2 rounded`}\n            onClick={disconnect}\n            disabled={!isRecording}\n          >\n            Stop\n          </button>\n        </div>\n      </div>\n      <div className=\"py-5 text-center text-white\">\n        {recognitionHistory.map((tx, idx) => (\n          <p key={idx}>{tx}</p>\n        ))}\n        <p>{currentRecognition}</p>\n      </div>\n    </div>\n  );\n}\nexport default SpeechToText;\n"],"mappings":";;AAAA;AACA;AACA;;AAGA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAIA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,QAAQ,EAAEC,MAAM,QAAQ,OAAO;AAC1D,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEvC,MAAMC,UAAU,GAAG,KAAK;AAExB,MAAMC,cAAc,GAAGA,CAAA,KACrBC,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;EAClCC,KAAK,EAAE;IACLC,QAAQ,EAAE,SAAS;IACnBN,UAAU,EAAEA,UAAU;IACtBO,UAAU,EAAE,EAAE;IACdC,YAAY,EAAE;EAChB,CAAC;EACDC,KAAK,EAAE;AACT,CAAC,CAAC;AAEJ,MAAMC,YAAY,GAAGA,CAAA,KAAM;EAAAC,EAAA;EACzB,MAAM,CAACC,UAAU,EAAEC,aAAa,CAAC,GAAGlB,QAAQ,CAAC,CAAC;EAC9C,MAAM,CAACmB,kBAAkB,EAAEC,qBAAqB,CAAC,GAAGpB,QAAQ,CAAC,CAAC;EAC9D,MAAM,CAACqB,kBAAkB,EAAEC,qBAAqB,CAAC,GAAGtB,QAAQ,CAAC,EAAE,CAAC;EAChE,MAAM,CAACuB,WAAW,EAAEC,cAAc,CAAC,GAAGxB,QAAQ,CAAC,KAAK,CAAC;EACrD,MAAM,CAACyB,QAAQ,EAAEC,WAAW,CAAC,GAAG1B,QAAQ,CAAC,CAAC;EAC1C,MAAM2B,YAAY,GAAG1B,MAAM,CAAC,CAAC;EAC7B,MAAM2B,eAAe,GAAG3B,MAAM,CAAC,CAAC;EAChC,MAAM4B,aAAa,GAAG5B,MAAM,CAAC,CAAC;EAE9B,MAAM6B,gBAAgB,GAAIC,IAAI,IAAK;IACjC,IAAIA,IAAI,CAACC,OAAO,EAAE;MAChBZ,qBAAqB,CAAC,KAAK,CAAC;MAC5B;MACAE,qBAAqB,CAAEW,GAAG,IAAK,CAAC,GAAGA,GAAG,EAAEF,IAAI,CAACG,IAAI,CAAC,CAAC;IACrD,CAAC,MAAMd,qBAAqB,CAACW,IAAI,CAACG,IAAI,GAAG,KAAK,CAAC;EACjD,CAAC;EAEDnC,SAAS,CAAC,MAAM;IACdoC,OAAO,CAACC,GAAG,CAAC,wBAAwB,EAAEf,kBAAkB,CAAC;EAC3D,CAAC,EAAE,CAACA,kBAAkB,CAAC,CAAC;EAExB,MAAMgB,OAAO,GAAGA,CAAA,KAAM;IACpBF,OAAO,CAACC,GAAG,CAAC,qBAAqB,CAAC;IAClCnB,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEqB,UAAU,CAAC,CAAC;IACxB,MAAMC,MAAM,GAAGrC,EAAE,CAACmC,OAAO,CAAC,uBAAuB,CAAC;IAClDE,MAAM,CAACC,EAAE,CAAC,SAAS,EAAE,MAAM;MACzBL,OAAO,CAACC,GAAG,CAAC,WAAW,EAAEG,MAAM,CAACE,EAAE,CAAC;MACnCvB,aAAa,CAACqB,MAAM,CAAC;IACvB,CAAC,CAAC;IAEFA,MAAM,CAACG,IAAI,CAAC,cAAc,EAAE,aAAa,CAAC;IAE1CH,MAAM,CAACG,IAAI,CAAC,wBAAwB,CAAC;IAErCH,MAAM,CAACC,EAAE,CAAC,iBAAiB,EAAGT,IAAI,IAAK;MACrCI,OAAO,CAACC,GAAG,CAAC,kBAAkB,EAAEL,IAAI,CAAC;IACvC,CAAC,CAAC;IAEFQ,MAAM,CAACC,EAAE,CAAC,oBAAoB,EAAGT,IAAI,IAAK;MACxCD,gBAAgB,CAACC,IAAI,CAAC;MACtBI,OAAO,CAACC,GAAG,CAAC,qBAAqB,EAAEL,IAAI,CAAC;IAC1C,CAAC,CAAC;IAEFQ,MAAM,CAACC,EAAE,CAAC,YAAY,EAAE,MAAM;MAC5BL,OAAO,CAACC,GAAG,CAAC,cAAc,EAAEG,MAAM,CAACE,EAAE,CAAC;IACxC,CAAC,CAAC;EACJ,CAAC;EAED,MAAMH,UAAU,GAAGA,CAAA,KAAM;IAAA,IAAAK,qBAAA,EAAAC,qBAAA,EAAAC,qBAAA;IACvB,IAAI,CAAC5B,UAAU,EAAE;IACjBA,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEyB,IAAI,CAAC,sBAAsB,CAAC;IACxCzB,UAAU,aAAVA,UAAU,uBAAVA,UAAU,CAAEqB,UAAU,CAAC,CAAC;IACxB,CAAAK,qBAAA,GAAAhB,YAAY,CAACmB,OAAO,cAAAH,qBAAA,uBAApBA,qBAAA,CAAsBL,UAAU,CAAC,CAAC;IAClC,CAAAM,qBAAA,GAAAf,aAAa,CAACiB,OAAO,cAAAF,qBAAA,uBAArBA,qBAAA,CAAuBN,UAAU,CAAC,CAAC;IACnC,CAAAO,qBAAA,GAAAjB,eAAe,CAACkB,OAAO,cAAAD,qBAAA,uBAAvBA,qBAAA,CAAyBE,KAAK,CAAC,CAAC;IAChC7B,aAAa,CAAC8B,SAAS,CAAC;IACxBtB,WAAW,CAACsB,SAAS,CAAC;IACtBxB,cAAc,CAAC,KAAK,CAAC;;IAErB;IACA;IACAyB,KAAK,CAACC,IAAI,CAAC,gCAAgC,EAAE;MAAE,YAAY,EAAE7B;IAAmB,CAAC,CAAC;IAClFD,qBAAqB,CAAC,EAAE,CAAC;IACzBE,qBAAqB,CAAC,EAAE,CAAC;EAC3B,CAAC;EAEDvB,SAAS,CAAC,MAAM;IACd,CAAC,YAAY;MACX,IAAIkB,UAAU,EAAE;QACd,IAAIM,WAAW,EAAE;UACf;QACF;QAEA,MAAM4B,MAAM,GAAG,MAAM7C,cAAc,CAAC,CAAC;QAErCsB,eAAe,CAACkB,OAAO,GAAG,IAAIM,MAAM,CAACC,YAAY,CAAC,CAAC;QAEnD,MAAMzB,eAAe,CAACkB,OAAO,CAACQ,YAAY,CAACC,SAAS,CAClD,2CACF,CAAC;QAED3B,eAAe,CAACkB,OAAO,CAACU,MAAM,CAAC,CAAC;QAEhC3B,aAAa,CAACiB,OAAO,GACnBlB,eAAe,CAACkB,OAAO,CAACW,uBAAuB,CAACN,MAAM,CAAC;QAEzDxB,YAAY,CAACmB,OAAO,GAAG,IAAIY,gBAAgB,CACzC9B,eAAe,CAACkB,OAAO,EACvB,kBACF,CAAC;QAEDnB,YAAY,CAACmB,OAAO,CAACT,OAAO,CAACT,eAAe,CAACkB,OAAO,CAACa,WAAW,CAAC;QACjE/B,eAAe,CAACkB,OAAO,CAACU,MAAM,CAAC,CAAC;QAEhC3B,aAAa,CAACiB,OAAO,CAACT,OAAO,CAACV,YAAY,CAACmB,OAAO,CAAC;QAEnDnB,YAAY,CAACmB,OAAO,CAACc,IAAI,CAACC,SAAS,GAAIC,KAAK,IAAK;UAC/C,MAAMC,SAAS,GAAGD,KAAK,CAAC/B,IAAI;UAC5Bd,UAAU,CAACyB,IAAI,CAAC,iBAAiB,EAAE;YAAEhC,KAAK,EAAEqD;UAAU,CAAC,CAAC;QAC1D,CAAC;QACDvC,cAAc,CAAC,IAAI,CAAC;MACtB,CAAC,MAAM;QACLW,OAAO,CAAC6B,KAAK,CAAC,eAAe,CAAC;MAChC;IACF,CAAC,EAAE,CAAC;IACJ,OAAO,MAAM;MACX,IAAIzC,WAAW,EAAE;QAAA,IAAA0C,sBAAA,EAAAC,sBAAA,EAAAC,sBAAA;QACf,CAAAF,sBAAA,GAAAtC,YAAY,CAACmB,OAAO,cAAAmB,sBAAA,uBAApBA,sBAAA,CAAsB3B,UAAU,CAAC,CAAC;QAClC,CAAA4B,sBAAA,GAAArC,aAAa,CAACiB,OAAO,cAAAoB,sBAAA,uBAArBA,sBAAA,CAAuB5B,UAAU,CAAC,CAAC;QACnC,IAAI,EAAA6B,sBAAA,GAAAvC,eAAe,CAACkB,OAAO,cAAAqB,sBAAA,uBAAvBA,sBAAA,CAAyBC,KAAK,MAAK,QAAQ,EAAE;UAAA,IAAAC,sBAAA;UAC/C,CAAAA,sBAAA,GAAAzC,eAAe,CAACkB,OAAO,cAAAuB,sBAAA,uBAAvBA,sBAAA,CAAyBtB,KAAK,CAAC,CAAC;QAClC;MACF;IACF,CAAC;EACH,CAAC,EAAE,CAAC9B,UAAU,EAAEM,WAAW,EAAEE,QAAQ,CAAC,CAAC;;EAEvC;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;EACA;;EAGA,oBACErB,OAAA;IAAKkE,SAAS,EAAC,kBAAkB;IAAAC,QAAA,gBAC/BnE,OAAA;MAAKkE,SAAS,EAAC,wCAAwC;MAAAC,QAAA,eACrDnE,OAAA;QAAKkE,SAAS,EAAC,WAAW;QAAAC,QAAA,gBACxBnE,OAAA;UACEkE,SAAS,EAAG,GAAE/C,WAAW,GAAG,YAAY,GAAG,2CACxC,oBAAoB;UACvBiD,OAAO,EAAEnC,OAAQ;UACjBoC,QAAQ,EAAElD,WAAY;UAAAgD,QAAA,EACvB;QAED;UAAAG,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC,eACTzE,OAAA;UACEkE,SAAS,EAAG,6DAA6D;UACzEE,OAAO,EAAElC,UAAW;UACpBmC,QAAQ,EAAE,CAAClD,WAAY;UAAAgD,QAAA,EACxB;QAED;UAAAG,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAQ,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACN;IAAC;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACH,CAAC,eACNzE,OAAA;MAAKkE,SAAS,EAAC,6BAA6B;MAAAC,QAAA,GACzClD,kBAAkB,CAACyD,GAAG,CAAC,CAACC,EAAE,EAAEC,GAAG,kBAC9B5E,OAAA;QAAAmE,QAAA,EAAcQ;MAAE,GAARC,GAAG;QAAAN,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAS,CACrB,CAAC,eACFzE,OAAA;QAAAmE,QAAA,EAAIpD;MAAkB;QAAAuD,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAAI,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACxB,CAAC;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACH,CAAC;AAEV,CAAC;AAAA7D,EAAA,CAnLKD,YAAY;AAAAkE,EAAA,GAAZlE,YAAY;AAoLlB,eAAeA,YAAY;AAAC,IAAAkE,EAAA;AAAAC,YAAA,CAAAD,EAAA"},"metadata":{},"sourceType":"module","externalDependencies":[]}